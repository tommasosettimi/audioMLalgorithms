# audioMLalgorithms

This repository contains Machine Learning and Deep Learning algorithms and models (music information retrieval, features extraction, classification et similia) for audio applications. There are various folders, specifically:

- **DL-audio-classical-instrument-classifier**: algorithm for audio feature extraction and classification of classical musical **instrument** (violin, clarinet, cello ...) using a combination of Machine Learning (Support Vector Machines, K-Nearest Neighbours) and Deep Learning (Multilayer Perceptron) techniques and the Essentia library.

- **DL-audio-instrument-material-classifier**: algorithm for audio feature extraction and classification of classical musical instrument construction **material** (wood, plastic, metal ...) using a combination of Machine Learning (Support Vector Machines, K-Nearest Neighbours) and Deep Learning (Multilayer Perceptron) techniques and the Essentia library.

- **DL-music-genre-classification**:  algorithm for  music **genre** classification of audio samples using a combination of Machine Learning (Logistic Regression, Support Vector Machines, ) and Deep Learning (Multi-layer Perceptron Classifier) techniques.

#

## DL-audio-classical-instrument-classifier


### Summary

The model was developed using a combination of Machine Learning (Support Vector Machine, K-Nearest Neighbours) and Deep Learning (Multilayer perceptron) techniques for feature extraction and classification.
The project is divided into three parts: feature extraction, classification and visualisation. The python jupyter notebook is located in the 'notebooks' folder. Feature extraction is performed using the Essentia library (open-source C++ library for audio analysis and audio-based music information retrieval) and Support Vector Machines. An initial classification is performed using neural networks (Multilayer Perceptron), followed by a second classification (K-Nearest Neighbours) and data visualisation.


### Dataset

The dataset used for this project is GoodSounds Dataset from Pompeu Fabra University (Barcelona, Spain). [Here](https://www.upf.edu/web/mtg/good-sounds) you can find more information on this dataset.

### Credits

This project was developed as part of the 'Music Information Retrieval' [course](https://www.upf.edu/web/smc/music-information-retrieval) of the master's programme 'Sound and Music Computing' at Pompeu Fabra University (Barcelona, Spain).


#

## DL-audio-instrument-material-classifier

### Summary

The model was developed using a combination of Machine Learning (Support Vector Machine, K-Nearest Neighbours) and Deep Learning (Multilayer perceptron) techniques for feature extraction and classification.
The project is divided into three parts: feature extraction, classification and visualisation. In the 'notebooks' folder are two python jupyter notebooks: 

1) In 'feature_extraction_MLP.ipynb' feature extraction is performed using the Essentia library (open-source C++ library for audio analysis and audio-based music information retrieval) and SVM. An initial classification is performed using neural networks (Multilayer Perceptron).

2) In "classification_visualisation_KNN" a second classification (K-Nearest Neighbours) and visualisation of the data is performed.


### Dataset

The dataset used for this project is GoodSounds Dataset from Pompeu Fabra University (Barcelona, Spain). [Here](https://www.upf.edu/web/mtg/good-sounds) you can find more information on this dataset.

### Credits

This project was developed as part of the 'Music Information Retrieval' [course](https://www.upf.edu/web/smc/music-information-retrieval) of the master's programme 'Sound and Music Computing' at Pompeu Fabra University (Barcelona, Spain).



#

## DL-audio-instrument-material-classifier

### Summary

The model was developed using a combination of Machine Learning (Support Vector Machine, K-Nearest Neighbours) and Deep Learning (Multilayer perceptron) techniques for feature extraction and classification.
The project is divided into three parts: feature extraction, classification and visualisation. In the 'notebooks' folder are two python jupyter notebooks: 

1) In 'feature_extraction_MLP.ipynb' feature extraction is performed using the Essentia library (open-source C++ library for audio analysis and audio-based music information retrieval) and SVM. An initial classification is performed using neural networks (Multilayer Perceptron).

2) In "classification_visualisation_KNN" a second classification (K-Nearest Neighbours) and visualisation of the data is performed.


### Dataset

The dataset used for this project is GoodSounds Dataset from Pompeu Fabra University (Barcelona, Spain). [Here](https://www.upf.edu/web/mtg/good-sounds) you can find more information on this dataset.

### Credits

This project was developed as part of the 'Music Information Retrieval' [course](https://www.upf.edu/web/smc/music-information-retrieval) of the master's programme 'Sound and Music Computing' at Pompeu Fabra University (Barcelona, Spain).


